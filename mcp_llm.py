# mcp_llm.py (Î¶¨Ìå©ÌÜ†ÎßÅ)
import os, re, json, time, asyncio
from typing import Dict, Any, Optional
from dotenv import load_dotenv

from openai import OpenAI
from mcp import ClientSession
from mcp.client.sse import sse_client

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL   = os.getenv("OPENAI_MODEL", "gpt-5-mini")
MCP_SSE_URL    = os.getenv("MCP_SSE_URL", "http://localhost:7456/sse")

POLL_INTERVAL  = float(os.getenv("ZAP_POLL_INTERVAL", "2.0"))
SPIDER_TIMEOUT = int(os.getenv("ZAP_SPIDER_TIMEOUT_SECS", "600"))
ASCAN_TIMEOUT  = int(os.getenv("ZAP_ASCAN_TIMEOUT_SECS", "1200"))

SYSTEM_FOR_SUMMARY = """ÎãπÏã†ÏùÄ Ïõπ Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖò Î≥¥Ïïà Î∂ÑÏÑù Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§.  
ÏûÖÎ†•ÏúºÎ°ú ZAP Ïä§Ï∫î Í≤∞Í≥º(ÏïåÎ¶º, URL/ÏÇ¨Ïù¥Ìä∏ Ïä§ÎãàÌé´, Î¶¨Ìè¨Ìä∏ Í≤ΩÎ°ú)ÏôÄ ÏÇ¨Ïö©ÏûêÍ∞Ä ÏßÄÏ†ïÌïú Focus Î™©Î°ùÏùÑ Î∞õÏäµÎãàÎã§.  

[Ïó≠Ìï†]
- Î≥¥Ïïà Ï†ÑÎ¨∏Í∞ÄÎ°úÏÑú Í∞úÎ∞úÏûê/Ïö¥ÏòÅÏûêÍ∞Ä Î∞îÎ°ú ÌôúÏö©Ìï† Ïàò ÏûàÎäî Í∞ÑÍ≤∞Ìïú Î≥¥Í≥†ÏÑúÎ•º ÏûëÏÑ±Ìï©ÎãàÎã§.
- Î∂àÌïÑÏöîÌïú ÎåÄÌôîÏ≤¥ÎÇò Ïû•Ìô©Ìïú ÏÑ§Î™ÖÏùÄ ÌïòÏßÄ ÏïäÏäµÎãàÎã§.
- Î™®Îì† Ï∂úÎ†•ÏùÄ Markdown ÌòïÏãùÏúºÎ°ú, Í∑úÍ≤©ÌôîÎêú Íµ¨Ï°∞Î•º Îî∞Î¶ÖÎãàÎã§.

[Ï∂úÎ†• Í∑úÍ≤©]
# üìå Î≥¥Ïïà Î∂ÑÏÑù ÏöîÏïΩ

## ‚úÖ ÏöîÏïΩ (3Ï§Ñ Ïù¥ÎÇ¥)
- ÌïµÏã¨ Ï∑®ÏïΩÏ†ê ÌòÑÌô© ÏöîÏïΩ (Ïòà: "Í≥†ÏúÑÌóò 2Í±¥, Ï§ëÏúÑÌóò 3Í±¥ Î∞úÍ≤¨")

## üìÑ ÏÉÅÏÑ∏ Í≤∞Í≥º
- **High ÏúÑÌóò**
  - [Ï∑®ÏïΩÏ†êÎ™Ö]: ÏòÅÌñ• URL (Í∞ÑÎã® ÏÑ§Î™Ö)
- **Medium ÏúÑÌóò**
  - [Ï∑®ÏïΩÏ†êÎ™Ö]: ÏòÅÌñ• URL (Í∞ÑÎã® ÏÑ§Î™Ö)
- **Low ÏúÑÌóò**
  - [Ï∑®ÏïΩÏ†êÎ™Ö]: ÏòÅÌñ• URL (Í∞ÑÎã® ÏÑ§Î™Ö)

## üîê Í∂åÍ≥† ÏÇ¨Ìï≠
- Ï∑®ÏïΩÏ†êÎ≥Ñ Ï£ºÏöî ÎåÄÏùëÏ±Ö (Ìï≠Î™©Î≥Ñ 1~2Ï§Ñ)
- Focus Î™©Î°ùÍ≥º Ïó∞Í≥ÑÎêú Î≥¥ÏôÑ Ìè¨Ïù∏Ìä∏ Î™ÖÏãú

---

[ÏûëÏÑ± ÏõêÏπô]
1. Î∞òÎìúÏãú ÏúÑ Íµ¨Ï°∞Î•º Ïú†ÏßÄÌï©ÎãàÎã§.
2. Í∞Å Ìï≠Î™©ÏùÄ 1~2Ï§Ñ Ïù¥ÎÇ¥Î°ú ÏöîÏïΩÌï©ÎãàÎã§.
3. Íµ¨Ï≤¥Ï†ÅÏù¥ÏßÄ ÏïäÏùÄ Î¨∏Íµ¨("Ï°∞Ïπò ÌïÑÏöî")Îäî ÌîºÌïòÍ≥†, Ïã§Î¨¥Ï†Å Í∂åÍ≥†(Ïòà: Prepared Statement Ï†ÅÏö©, CSP Ï∂îÍ∞Ä)Î•º Ï†úÏãúÌï©ÎãàÎã§.
4. ÎåÄÌôîÏ≤¥, Î∂àÌïÑÏöîÌïú ÏÑúÎëê/Í≤∞Î°† Î¨∏Íµ¨Îäî Ï†àÎåÄ Ìè¨Ìï®ÌïòÏßÄ ÏïäÏäµÎãàÎã§.
ÎãπÏã†ÏùÄ Ïõπ Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖò Î≥¥Ïïà Î∂ÑÏÑù Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§.  
ÏûÖÎ†•ÏúºÎ°ú ZAP Ïä§Ï∫î Í≤∞Í≥º(ÏïåÎ¶º, URL/ÏÇ¨Ïù¥Ìä∏ Ïä§ÎãàÌé´, Î¶¨Ìè¨Ìä∏ Í≤ΩÎ°ú)ÏôÄ ÏÇ¨Ïö©ÏûêÍ∞Ä ÏßÄÏ†ïÌïú Focus Î™©Î°ùÏùÑ Î∞õÏäµÎãàÎã§.  

[Ïó≠Ìï†]
- Î≥¥Ïïà Ï†ÑÎ¨∏Í∞ÄÎ°úÏÑú Í∞úÎ∞úÏûê/Ïö¥ÏòÅÏûêÍ∞Ä Î∞îÎ°ú ÌôúÏö©Ìï† Ïàò ÏûàÎäî Í∞ÑÍ≤∞Ìïú Î≥¥Í≥†ÏÑúÎ•º ÏûëÏÑ±Ìï©ÎãàÎã§.
- Î∂àÌïÑÏöîÌïú ÎåÄÌôîÏ≤¥ÎÇò Ïû•Ìô©Ìïú ÏÑ§Î™ÖÏùÄ ÌïòÏßÄ ÏïäÏäµÎãàÎã§.
- Î™®Îì† Ï∂úÎ†•ÏùÄ Markdown ÌòïÏãùÏúºÎ°ú, Í∑úÍ≤©ÌôîÎêú Íµ¨Ï°∞Î•º Îî∞Î¶ÖÎãàÎã§.

[Ï∂úÎ†• Í∑úÍ≤©]
# üìå Î≥¥Ïïà Î∂ÑÏÑù ÏöîÏïΩ

## ‚úÖ ÏöîÏïΩ (3Ï§Ñ Ïù¥ÎÇ¥)
- ÌïµÏã¨ Ï∑®ÏïΩÏ†ê ÌòÑÌô© ÏöîÏïΩ (Ïòà: "Í≥†ÏúÑÌóò 2Í±¥, Ï§ëÏúÑÌóò 3Í±¥ Î∞úÍ≤¨")

## üìÑ ÏÉÅÏÑ∏ Í≤∞Í≥º
- **High ÏúÑÌóò**
  - [Ï∑®ÏïΩÏ†êÎ™Ö]: ÏòÅÌñ• URL (Í∞ÑÎã® ÏÑ§Î™Ö)
- **Medium ÏúÑÌóò**
  - [Ï∑®ÏïΩÏ†êÎ™Ö]: ÏòÅÌñ• URL (Í∞ÑÎã® ÏÑ§Î™Ö)
- **Low ÏúÑÌóò**
  - [Ï∑®ÏïΩÏ†êÎ™Ö]: ÏòÅÌñ• URL (Í∞ÑÎã® ÏÑ§Î™Ö)

## üîê Í∂åÍ≥† ÏÇ¨Ìï≠
- Ï∑®ÏïΩÏ†êÎ≥Ñ Ï£ºÏöî ÎåÄÏùëÏ±Ö (Ìï≠Î™©Î≥Ñ 1~2Ï§Ñ)
- Focus Î™©Î°ùÍ≥º Ïó∞Í≥ÑÎêú Î≥¥ÏôÑ Ìè¨Ïù∏Ìä∏ Î™ÖÏãú

---

[ÏûëÏÑ± ÏõêÏπô]
1. Î∞òÎìúÏãú ÏúÑ Íµ¨Ï°∞Î•º Ïú†ÏßÄÌï©ÎãàÎã§.
2. Í∞Å Ìï≠Î™©ÏùÄ 1~2Ï§Ñ Ïù¥ÎÇ¥Î°ú ÏöîÏïΩÌï©ÎãàÎã§.
3. Íµ¨Ï≤¥Ï†ÅÏù¥ÏßÄ ÏïäÏùÄ Î¨∏Íµ¨("Ï°∞Ïπò ÌïÑÏöî")Îäî ÌîºÌïòÍ≥†, Ïã§Î¨¥Ï†Å Í∂åÍ≥†(Ïòà: Prepared Statement Ï†ÅÏö©, CSP Ï∂îÍ∞Ä)Î•º Ï†úÏãúÌï©ÎãàÎã§.
4. ÎåÄÌôîÏ≤¥, Î∂àÌïÑÏöîÌïú ÏÑúÎëê/Í≤∞Î°† Î¨∏Íµ¨Îäî Ï†àÎåÄ Ìè¨Ìï®ÌïòÏßÄ ÏïäÏäµÎãàÎã§.
5. Focus Î™©Î°ùÏóê Î™ÖÏãúÎêú Ìï≠Î™©Í≥º Í¥ÄÎ†®Îêú Ï∑®ÏïΩÏ†êÏùÄ Î∞òÎìúÏãú Ïñ∏Í∏âÌï©ÎãàÎã§.
"""

# --- Í∏∞Ï°¥ Ïú†Ìã∏ Ìï®Ïàò (ÏÉùÎûµ ÏóÜÏù¥ Ïú†ÏßÄ) ---
def blocks_to_text(blocks) -> str:
    parts=[]
    for b in blocks:
        if getattr(b,"type","") == "text":
            parts.append(getattr(b,"text","") or "")
        else:
            d=getattr(b,"data",None)
            if d is not None:
                try: parts.append(json.dumps(d, ensure_ascii=False))
                except Exception: parts.append(str(d))
    return "\n".join([p for p in parts if p]).strip()

def parse_scan_id(text: str) -> Optional[str]:
    m = re.search(r'\b(scanId|scan)\b\D+(\d+)', text, re.I)
    return m.group(2) if m else None

def parse_percent(text: str) -> Optional[int]:
    m = re.search(r'"status"\s*:\s*"?(?P<p>\d{1,3})"?', text, re.I)
    if m: return max(0, min(100, int(m.group("p"))))
    m = re.search(r'(\d{1,3})\s*%', text)
    if m: return max(0, min(100, int(m.group(1))))
    m = re.search(r'\b(\d{1,3})\b', text)
    if m: return max(0, min(100, int(m.group(1))))
    return None

def pick_key(props: Dict[str, Any], *cands):
    props = props or {}
    lower = {k.lower(): k for k in props.keys()}
    for cand in cands:
        cl = cand.lower()
        for lk, orig in lower.items():
            if cl in lk:
                return orig
    return next(iter(props.keys())) if props else None

async def call_tool(session: ClientSession, name: str, args: Dict[str, Any]) -> str:
    res = await session.call_tool(name, args)
    return blocks_to_text(res.content) or "(empty)"

# --- Spider (Ï†ïÏ†Å Î∂ÑÏÑù) ---
async def run_spider(session: ClientSession, target_url: str) -> Dict[str, Any]:
    results = {"target": target_url}
    tl = await session.list_tools()
    schema = {t.name: (t.inputSchema or {"type":"object","properties":{}}) for t in tl.tools}
    props  = {n: (schema[n].get("properties") or {}) for n in schema}

    if "zap_spider" not in schema or "zap_spider_status" not in schema:
        raise RuntimeError("MCP server does not expose spider tools")

    sp_p = props["zap_spider"]
    sp_url_key = pick_key(sp_p, "url", "targetUrl", "baseUrl", "base", "target")
    spider_txt = await call_tool(session, "zap_spider", {sp_url_key: target_url})
    sid = parse_scan_id(spider_txt)
    if not sid:
        raise RuntimeError(f"Spider did not return scanId: {spider_txt}")

    st_p = props["zap_spider_status"]
    sid_key = pick_key(st_p, "scanId", "scan", "id")

    t0 = time.time()
    while True:
        stat = await call_tool(session, "zap_spider_status", {sid_key: sid})
        pct = parse_percent(stat) or 0
        if pct >= 100: break
        if time.time()-t0 > SPIDER_TIMEOUT: raise TimeoutError("Spider timed out")
        await asyncio.sleep(POLL_INTERVAL)

    # ÏÇ¨Ïù¥Ìä∏/URL ÏÉòÌîå ÏàòÏßë
    if "zap_sites" in schema:
        results["sites"] = await call_tool(session, "zap_sites", {})
    if "zap_urls" in schema:
        up = props["zap_urls"]
        base_key = pick_key(up, "baseUrl", "base", "url")
        results["urls_sample"] = await call_tool(session, "zap_urls", {base_key: target_url})
    return results

# --- Active Scan (ÎèôÏ†Å Î∂ÑÏÑù) ---
async def run_active_scan(session: ClientSession, target_url: str) -> Dict[str, Any]:
    results = {"target": target_url}
    tl = await session.list_tools()
    schema = {t.name: (t.inputSchema or {"type":"object","properties":{}}) for t in tl.tools}
    props  = {n: (schema[n].get("properties") or {}) for n in schema}

    if "zap_active_scan" not in schema or "zap_active_scan_status" not in schema:
        raise RuntimeError("MCP server does not expose active scan tools")

    as_p = props["zap_active_scan"]
    as_url_key = pick_key(as_p, "url", "targetUrl", "baseUrl", "base", "target")
    as_args = {as_url_key: target_url}
    rec_key = pick_key(as_p, "recurse", "recursive")
    if rec_key: as_args[rec_key] = True

    ascan_txt = await call_tool(session, "zap_active_scan", as_args)
    aid = parse_scan_id(ascan_txt)
    if not aid:
        raise RuntimeError(f"Active scan did not return scanId: {ascan_txt}")

    ast_p = props["zap_active_scan_status"]
    aid_key = pick_key(ast_p, "scanId", "scan", "id")

    t1 = time.time()
    while True:
        stat = await call_tool(session, "zap_active_scan_status", {aid_key: aid})
        pct = parse_percent(stat) or 0
        if pct >= 100: break
        if time.time()-t1 > ASCAN_TIMEOUT: raise TimeoutError("Active scan timed out")
        await asyncio.sleep(POLL_INTERVAL)

    if "zap_alerts" in schema:
        ap = props["zap_alerts"]
        base_key = pick_key(ap, "base", "baseUrl", "url")
        results["alerts"] = await call_tool(session, "zap_alerts", {base_key: target_url})

    return results

# --- ÏµúÏ¢Ö Ïã§Ìñâ Ìï®Ïàò ---
async def run(target_url: str, focus: Optional[str], openapi_url: Optional[str], sse_url: str, do_active: bool = True):
    if not OPENAI_API_KEY: raise SystemExit("Set OPENAI_API_KEY")
    client = OpenAI(api_key=OPENAI_API_KEY)

    async with sse_client(url=sse_url) as (read, write):
        async with ClientSession(read, write) as session:
            await session.initialize()

            # Spider Î®ºÏ†Ä
            artifacts = await run_spider(session, target_url)

            # Active ScanÏùÄ ÏòµÏÖò
            if do_active:
                active_results = await run_active_scan(session, target_url)
                artifacts.update(active_results)

    # Advisory ÏÉùÏÑ±
    payload = f"Target: {target_url}\nFocus: {focus}\n\nArtifacts:\n{json.dumps(artifacts, indent=2, ensure_ascii=False)}"
    messages = [
        {"role": "system", "content": SYSTEM_FOR_SUMMARY},
        {"role": "user", "content": payload},
    ]
    resp = client.chat.completions.create(model=OPENAI_MODEL, messages=messages)
    print("\n==== Advisory ====\n")
    print(resp.choices[0].message.content or "(no advisory text produced)")
    return artifacts

